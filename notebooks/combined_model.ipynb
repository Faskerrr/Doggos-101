{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os,sys\nimport cv2\nfrom tqdm import tqdm\nimport re\nimport random\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\n\nfrom tensorflow.keras import models, Sequential, layers, regularizers, Model\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.utils import image_dataset_from_directory \nimport tensorflow.keras.applications.resnet50 as resnet50\nimport tensorflow.keras.applications.inception_v3 as inception_v3\n\nfrom tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess_input\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess_input\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-24T15:31:47.945945Z","iopub.execute_input":"2023-03-24T15:31:47.946754Z","iopub.status.idle":"2023-03-24T15:31:55.064961Z","shell.execute_reply.started":"2023-03-24T15:31:47.946714Z","shell.execute_reply":"2023-03-24T15:31:55.063805Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"path_train = '/kaggle/input/stanford-dogs-dataset-traintest/cropped/train'\npath_test = '/kaggle/input/stanford-dogs-dataset-traintest/cropped/test'","metadata":{"execution":{"iopub.status.busy":"2023-03-24T15:31:58.533488Z","iopub.execute_input":"2023-03-24T15:31:58.534992Z","iopub.status.idle":"2023-03-24T15:31:58.540252Z","shell.execute_reply.started":"2023-03-24T15:31:58.534934Z","shell.execute_reply":"2023-03-24T15:31:58.538948Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"# Function for plotting the loss and accuracy \ndef plot_history(history, title='', axs=None, exp_name=\"\"):\n    if axs is not None:\n        ax1, ax2 = axs\n    else:\n        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    \n    if len(exp_name) > 0 and exp_name[0] != '_':\n        exp_name = '_' + exp_name\n    ax1.plot(history.history['loss'], label='train' + exp_name)\n    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n    #ax1.set_ylim(0., 2.2)\n    ax1.set_title('loss')\n    ax1.legend()\n\n    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n    #ax2.set_ylim(0.25, 1.)\n    ax2.set_title('Accuracy')\n    ax2.legend()\n    return (ax1, ax2)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T15:32:00.356062Z","iopub.execute_input":"2023-03-24T15:32:00.356454Z","iopub.status.idle":"2023-03-24T15:32:00.366845Z","shell.execute_reply.started":"2023-03-24T15:32:00.356418Z","shell.execute_reply":"2023-03-24T15:32:00.365686Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"# TRAIN DATASET\ntrain_dataset = image_dataset_from_directory(directory=path_train,\n                                      labels='inferred',\n                                      label_mode=\"categorical\",\n                                      validation_split=None,\n                                      subset=None,\n                                      seed=123,\n                                      image_size=(224, 224),\n                                      batch_size=32)   \n\n# Preprocess X in the train_dataset\n# train_ds_prepro = train_dataset.map(preprocess)\n\n###########\n# VALIDATION DATASET\n# val_dataset = image_dataset_from_directory(directory=path_train,\n#                                       labels='inferred',\n#                                       label_mode=\"categorical\",\n#                                       validation_split=0.2,\n#                                       subset=\"validation\",\n#                                       seed=123,\n#                                       image_size=(224, 224),\n#                                       batch_size=32)\n                                         \n# Preprocess X in the val_dataset\n# validation_ds_prepro = val_dataset.map(preprocess)\n\n############\n# TEST DATASET\ntest_dataset = image_dataset_from_directory(directory=path_test,\n                                            labels='inferred',\n                                            label_mode=\"categorical\",\n                                            validation_split=None,\n                                            subset=None,\n                                            seed=123,\n                                            image_size=(224, 224),\n                                            batch_size=32) \n\n# Preprocess X in the test_dataset\n# test_ds_prepro = test_dataset.map(preprocess)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T16:19:44.026180Z","iopub.execute_input":"2023-03-24T16:19:44.026555Z","iopub.status.idle":"2023-03-24T16:20:00.538774Z","shell.execute_reply.started":"2023-03-24T16:19:44.026520Z","shell.execute_reply":"2023-03-24T16:20:00.537702Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Found 12000 files belonging to 120 classes.\nFound 8580 files belonging to 120 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"image_batch_train, labels_batch_train = next(iter(train_dataset))\nimage_batch_train.shape, labels_batch_train.shape\n","metadata":{"execution":{"iopub.status.busy":"2023-03-24T16:20:24.988050Z","iopub.execute_input":"2023-03-24T16:20:24.988757Z","iopub.status.idle":"2023-03-24T16:20:25.236814Z","shell.execute_reply.started":"2023-03-24T16:20:24.988711Z","shell.execute_reply":"2023-03-24T16:20:25.235641Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(TensorShape([32, 224, 224, 3]), TensorShape([32, 120]))"},"metadata":{}}]},{"cell_type":"markdown","source":"# Load pre-trained ResNet50 and Inception_V3 models ","metadata":{}},{"cell_type":"code","source":"# Load the ResNet50 model pre-trained on ImageNet\nbase_model_resnet50 = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n# Freeze the base model layers to prevent them from being updated during training\nbase_model_resnet50.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-03-24T15:33:05.924518Z","iopub.execute_input":"2023-03-24T15:33:05.925230Z","iopub.status.idle":"2023-03-24T15:33:10.976473Z","shell.execute_reply.started":"2023-03-24T15:33:05.925190Z","shell.execute_reply":"2023-03-24T15:33:10.975463Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 3s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the Inception_V3 model pre-trained on ImageNet\nbase_model_inceptionv3 = inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n# Freeze the base model layers to prevent them from being updated during training\nbase_model_inceptionv3.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-03-24T15:33:24.433493Z","iopub.execute_input":"2023-03-24T15:33:24.434411Z","iopub.status.idle":"2023-03-24T15:33:29.962939Z","shell.execute_reply.started":"2023-03-24T15:33:24.434356Z","shell.execute_reply":"2023-03-24T15:33:29.961956Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87910968/87910968 [==============================] - 3s 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Combine the pre-trained layers ","metadata":{}},{"cell_type":"code","source":"# Get the output from Resnet50\ninput1 = layers.Input(shape=(224,224,3))\nx1 = resnet_preprocess_input(input1)\nx1 = base_model_resnet50(x1)\nx1 = layers.Flatten()(x1)\noutput_resnet50 = x1\noutput_resnet50","metadata":{"execution":{"iopub.status.busy":"2023-03-24T15:33:46.665239Z","iopub.execute_input":"2023-03-24T15:33:46.666169Z","iopub.status.idle":"2023-03-24T15:33:47.166884Z","shell.execute_reply.started":"2023-03-24T15:33:46.666101Z","shell.execute_reply":"2023-03-24T15:33:47.165699Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<KerasTensor: shape=(None, 100352) dtype=float32 (created by layer 'flatten')>"},"metadata":{}}]},{"cell_type":"code","source":"# Get the output from Inception_V3\ninput2 = layers.Input(shape=(224,224,3))\nx2 = inception_preprocess_input(input2)\nx2 = base_model_inceptionv3(x2)\nx2 = layers.Flatten()(x2)\noutput_inceptionv3 = x2\noutput_inceptionv3\n","metadata":{"execution":{"iopub.status.busy":"2023-03-24T15:33:48.639556Z","iopub.execute_input":"2023-03-24T15:33:48.640558Z","iopub.status.idle":"2023-03-24T15:33:49.291455Z","shell.execute_reply.started":"2023-03-24T15:33:48.640498Z","shell.execute_reply":"2023-03-24T15:33:49.289935Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<KerasTensor: shape=(None, 51200) dtype=float32 (created by layer 'flatten_1')>"},"metadata":{}}]},{"cell_type":"code","source":"# Combine the outputs\ncombined_output = layers.concatenate([output_resnet50, output_inceptionv3])\ncombined_output ","metadata":{"execution":{"iopub.status.busy":"2023-03-24T15:33:50.907463Z","iopub.execute_input":"2023-03-24T15:33:50.908186Z","iopub.status.idle":"2023-03-24T15:33:50.922331Z","shell.execute_reply.started":"2023-03-24T15:33:50.908144Z","shell.execute_reply":"2023-03-24T15:33:50.921169Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<KerasTensor: shape=(None, 151552) dtype=float32 (created by layer 'concatenate_2')>"},"metadata":{}}]},{"cell_type":"markdown","source":"# The combined model","metadata":{}},{"cell_type":"code","source":"# Initialize and compile\ninputs = [input1, input2]   #the same train data \n\nx = layers.Dense(100, activation=\"relu\")(combined_output)\nx = layers.Dense(100, activation=\"relu\")(x)\npred = layers.Dense(120, activation=\"softmax\")(x)\n\ncombined_model = Model(inputs=inputs, outputs=[pred, pred])\n\nopt = optimizers.Adam(learning_rate = 1e-4)\ncombined_model.compile(optimizer=opt, \n                       loss='categorical_crossentropy', \n                       metrics=['accuracy'])\n\ncombined_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-24T16:22:44.702539Z","iopub.execute_input":"2023-03-24T16:22:44.703253Z","iopub.status.idle":"2023-03-24T16:22:44.836825Z","shell.execute_reply.started":"2023-03-24T16:22:44.703215Z","shell.execute_reply":"2023-03-24T16:22:44.835553Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Model: \"model_3\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n input_4 (InputLayer)           [(None, 224, 224, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n tf.__operators__.getitem (Slic  (None, 224, 224, 3)  0          ['input_3[0][0]']                \n ingOpLambda)                                                                                     \n                                                                                                  \n tf.math.truediv (TFOpLambda)   (None, 224, 224, 3)  0           ['input_4[0][0]']                \n                                                                                                  \n tf.nn.bias_add (TFOpLambda)    (None, 224, 224, 3)  0           ['tf.__operators__.getitem[0][0]'\n                                                                 ]                                \n                                                                                                  \n tf.math.subtract (TFOpLambda)  (None, 224, 224, 3)  0           ['tf.math.truediv[0][0]']        \n                                                                                                  \n resnet50 (Functional)          (None, 7, 7, 2048)   23587712    ['tf.nn.bias_add[0][0]']         \n                                                                                                  \n inception_v3 (Functional)      (None, 5, 5, 2048)   21802784    ['tf.math.subtract[0][0]']       \n                                                                                                  \n flatten (Flatten)              (None, 100352)       0           ['resnet50[0][0]']               \n                                                                                                  \n flatten_1 (Flatten)            (None, 51200)        0           ['inception_v3[0][0]']           \n                                                                                                  \n concatenate_2 (Concatenate)    (None, 151552)       0           ['flatten[0][0]',                \n                                                                  'flatten_1[0][0]']              \n                                                                                                  \n dense_9 (Dense)                (None, 100)          15155300    ['concatenate_2[0][0]']          \n                                                                                                  \n dense_10 (Dense)               (None, 100)          10100       ['dense_9[0][0]']                \n                                                                                                  \n dense_11 (Dense)               (None, 120)          12120       ['dense_10[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 60,568,016\nTrainable params: 15,177,520\nNon-trainable params: 45,390,496\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the combined model \nMODEL = \"combined_model\"\n\nes = EarlyStopping(monitor='val_loss', \n                   mode='auto', \n                   patience=5, \n                   verbose=1, \n                   restore_best_weights=True)\n\nlr = ReduceLROnPlateau(monitor=\"val_loss\",\n                       factor = 0.1,\n                       patience=3,\n                       verbose=1,\n                       min_lr=0)\n\nmcp = ModelCheckpoint(\"{}.h5\".format(MODEL),\n                      save_weights_only=True,\n                      monitor='val_accuracy',\n                      mode='max',\n                      verbose=0,\n                      save_best_only=True)\n\nhistory = combined_model.fit(x=[image_batch_train, image_batch_train],\n                             y=labels_batch_train,\n                             validation_split=0.2, \n                             epochs=10,\n                             callbacks=[es, lr, mcp],\n                             batch_size=32,\n                             verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T16:22:47.642870Z","iopub.execute_input":"2023-03-24T16:22:47.643829Z","iopub.status.idle":"2023-03-24T16:23:01.990757Z","shell.execute_reply.started":"2023-03-24T16:22:47.643787Z","shell.execute_reply":"2023-03-24T16:23:01.989663Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Epoch 1/10\n1/1 [==============================] - 13s 13s/step - loss: 10.3866 - dense_11_loss: 5.1933 - dense_11_1_loss: 5.1933 - dense_11_accuracy: 0.0400 - dense_11_1_accuracy: 0.0400 - val_loss: 10.2977 - val_dense_11_loss: 5.1488 - val_dense_11_1_loss: 5.1488 - val_dense_11_accuracy: 0.0000e+00 - val_dense_11_1_accuracy: 0.0000e+00 - lr: 1.0000e-04\nEpoch 2/10\n1/1 [==============================] - 0s 210ms/step - loss: 5.3226 - dense_11_loss: 2.6613 - dense_11_1_loss: 2.6613 - dense_11_accuracy: 0.3600 - dense_11_1_accuracy: 0.3600 - val_loss: 10.7097 - val_dense_11_loss: 5.3549 - val_dense_11_1_loss: 5.3549 - val_dense_11_accuracy: 0.0000e+00 - val_dense_11_1_accuracy: 0.0000e+00 - lr: 1.0000e-04\nEpoch 3/10\n1/1 [==============================] - 0s 184ms/step - loss: 2.0417 - dense_11_loss: 1.0209 - dense_11_1_loss: 1.0209 - dense_11_accuracy: 0.8400 - dense_11_1_accuracy: 0.8400 - val_loss: 11.7864 - val_dense_11_loss: 5.8932 - val_dense_11_1_loss: 5.8932 - val_dense_11_accuracy: 0.1429 - val_dense_11_1_accuracy: 0.1429 - lr: 1.0000e-04\nEpoch 4/10\n1/1 [==============================] - ETA: 0s - loss: 0.7525 - dense_11_loss: 0.3763 - dense_11_1_loss: 0.3763 - dense_11_accuracy: 0.9200 - dense_11_1_accuracy: 0.9200\nEpoch 4: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n1/1 [==============================] - 0s 187ms/step - loss: 0.7525 - dense_11_loss: 0.3763 - dense_11_1_loss: 0.3763 - dense_11_accuracy: 0.9200 - dense_11_1_accuracy: 0.9200 - val_loss: 12.7920 - val_dense_11_loss: 6.3960 - val_dense_11_1_loss: 6.3960 - val_dense_11_accuracy: 0.1429 - val_dense_11_1_accuracy: 0.1429 - lr: 1.0000e-04\nEpoch 5/10\n1/1 [==============================] - 0s 186ms/step - loss: 0.2921 - dense_11_loss: 0.1461 - dense_11_1_loss: 0.1461 - dense_11_accuracy: 1.0000 - dense_11_1_accuracy: 1.0000 - val_loss: 12.8435 - val_dense_11_loss: 6.4217 - val_dense_11_1_loss: 6.4217 - val_dense_11_accuracy: 0.1429 - val_dense_11_1_accuracy: 0.1429 - lr: 1.0000e-05\nEpoch 6/10\n1/1 [==============================] - ETA: 0s - loss: 0.2626 - dense_11_loss: 0.1313 - dense_11_1_loss: 0.1313 - dense_11_accuracy: 1.0000 - dense_11_1_accuracy: 1.0000Restoring model weights from the end of the best epoch: 1.\n1/1 [==============================] - 1s 641ms/step - loss: 0.2626 - dense_11_loss: 0.1313 - dense_11_1_loss: 0.1313 - dense_11_accuracy: 1.0000 - dense_11_1_accuracy: 1.0000 - val_loss: 12.8596 - val_dense_11_loss: 6.4298 - val_dense_11_1_loss: 6.4298 - val_dense_11_accuracy: 0.1429 - val_dense_11_1_accuracy: 0.1429 - lr: 1.0000e-05\nEpoch 6: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"plot_history(combined_model, title=\"Model 3\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate MODEL 2 on the test dataset\nres = combined_model.evaluate(preprocessed_test_dataset)\ntest_accuracy = res[-1]\nprint(f\"test_accuracy_model_1 = {round(test_accuracy,2)*100} %\")\nprint(f'Chance level: {1./120*100:.1f}%')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T14:47:26.642900Z","iopub.status.idle":"2023-03-24T14:47:26.643280Z","shell.execute_reply.started":"2023-03-24T14:47:26.643093Z","shell.execute_reply":"2023-03-24T14:47:26.643112Z"},"trusted":true},"execution_count":null,"outputs":[]}]}